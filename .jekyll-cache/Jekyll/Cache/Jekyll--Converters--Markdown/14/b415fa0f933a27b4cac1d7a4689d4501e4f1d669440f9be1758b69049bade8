I"æ
<p>Hello! This post describes my experience presenting my paper (and winning the Best Paper Award :D) at AMLTA - 2020.</p>

<h2 id="paper-details">Paper Details</h2>

<p>I am the lead author of my first paper, ‚ÄúA Comparative Study of Model Free Reinforcement Learning Approaches‚Äù. The following is the abstract for a cursory understanding :</p>

<p class="abstract">This study explores and compares 3 model-free learning methods, namely, Deep Q-Networks(DQN), Dueling Deep Q-Networks(DDQN) and State - Action - Reward - State - Action (SARSA) while detailing the mathematical principles behind each method. These methods were chosen as to bring out the contrast between off-policy(DQN) and on-policy(SARSA) learners. The DDQN method was included as it is a modification of DQN. The results of these methods and their performance on the classic problem, CartPole were compared. Post training, testing results for each of the models were as follows: DQN obtained an average per episode reward of 496.36; its variant and improvement,
DDQN obtained a perfect score of 500 and SARSA obtained a score of 438.28. To conclude, the theoretical inferences were decisively reaffirmed with observations based on descriptive plots of training and testing results.</p>

<p>I wrote this paper in my junior year, and you can find the source code and related work <a href="https://github.com/anantmoudgalya/GamePlaying-RL">here</a>.</p>

<h2 id="at-the-conference">At the conference</h2>

<p>I had the pleasure of attending 3 great keynote speeches at the conference. <br />
I particularly remember <a href="https://www.csa.iisc.ac.in/~shalabh/index.html">Dr. Shalabh Bhatnagar</a>‚Äôs talk delivering an introduction to Stochastic Approximation in Machine Learning. 
It was a fast paced, yet detailed introduction into the topic. Although I couldn‚Äôt keep up with most of the mathematics, I was sure to note down things of interest and things I wanted to read more.
I got an understanding of the Robbins-Monro Algorithm, which after further reading, sparked my interest. He also cited a great publication for understanding stochastic approximation, the book on Parameter Optimization by VS Burkar. <br />
He also detailed his experimental results after multiple simulations of using Q Learning with Stochastic Approximation for Intelligent Traffic Control which were incredibly impressive, and had proved their effectiveness after implementing it at a nearby Traffic Signal.</p>

<p>The second talk that I really enjoyed was delivered by Mr. <a href="https://www.linkedin.com/in/iammastermac/">Shubham Gupta</a> of Dell Technologies. As ML is my domain of interest, his talk titled ‚ÄúIndustrial Challenges and Use Cases related to ML‚Äù was a must-attend.</p>
:ET